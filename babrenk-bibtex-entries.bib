%% LaTeX2e file `babrenk-bibtex-entries.bib'
%% generated by the `bibtex-entries' environment
%% from source `babrenk' on 2021/09/27.
%%


  @article{lda,
  author =       {David Meir Blei and Andrew Ng and Michael Irwin Jordan},
  title =        {Latent Dirichlet Allocation},
  journal =    {Journal of Machine Learning Research},
  year =         {2003},
  pages= {993--1022},
}
  @article{ptm,
  author =       {David Meir Blei},
  title =        {Probabilistic Topic Models},
  journal =    {Communication of the ACM},
  year =         {2012},
  pages={77--84},
}
  @article{plsa,
  author =       {Thomas Hofmann},
  title =        {Probabilistic Latent Semantic Analysis},
  journal =    {EECS Department Computer Science Division},
  year =         {1975},
  pages= {289--294},
}
  @article{a0,
  author =       {Hamed Jelodar and Yongli Wang and Chi Yuan},
  title =        {Latent Dirichlet allocation (LDA) and topic modeling: models, applications, a survey},
  journal =    {Springer},
  year =         {2019},
  pages = {2--32},
}
  @article{a1,
  author =       {Mohammadzaman Zamani and H. Andrew Schwartz and Johannes Eichstaedt},
  title =        {Understanding Weekly COVID-19 Concerns through Dynamic Content-Specific LDA Topic Modeling},
  journal =    {Proc Conf Empir Methods Nat Lang Process},
  year =         {2020},
  pages ={1--6},
}
@INPROCEEDINGS{KuhBeBrMo20b,
author={Felix Kuhr and Magnus Bender and Tanya Braun and Ralf M\"oller},
title={{Maintaining Topic Models for Growing Corpora}},
booktitle={Proceedings of the 14th IEEE International Conference on Semantic Computing (ICSC-20)},
year={2020},
pages     = {451--458},
publisher = {IEEE},
doi={https://doi.org/10.1109/ICSC.2020.00017},
ISSN={},
keywords={Topic Models;Machine Learning;Text Mining}
}
@inproceedings{rehurek_lrec,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}
  @manual{towardsdata,
  address =       {https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24},
  title =        {Topic Modeling and Latent Dirichlet Allocation(LDA) in Python},
  year =    {2018},
  author = {Susan Li},
  organization = {Towards Data Science Inc.},
  urldate= {2021-09-20},
}
  @manual{towardsdat,
  address =       {https://towardsdatascience.com/lda-topic-modeling-an-explanation-e184c90aadcd},
  title =        {LDA Topic Modeling An Explanation},
  year =    {2018},
  author= {Tyler Doll},
  organization= {Towards Data Science Inc.},
 urldate= {2021-09-21},
}
  @manual{lda2,
  address =       {https://medium.com/analytics-vidhya/topic-modeling-using-lda-and-gibbs-sampling-explained-49d49b3d1045},
  title =        {Topic modeling using Latent Dirichlet Allocation (LDA) and Gibbs Sampling explained},
  year =    {2018},
  author= {Ankur Tomar},
  organization= {Analytics Vidhya},
   urldate= {2021-09-21},
}
  @manual{radim,
  address =       {https://radimrehurek.com/gensim/models/ldamodel.html},
  title =        {LDA Model},
  year =    {2009},
  author= {Radim Rehurek},
  organization= {Gensim},
   urldate= {2021-09-21},
}
  @manual{radim2,
  address =       {https://radimrehurek.com/gensim/models/ldamulticore.htm},
  title =        {Parallelized Latent Dirichlet Allocation},
  year =    {2009},
  author= {Radim Rehurek},
  organization= {Gensim},
 urldate= {2021-09-21},
}
  @book{tmbook,
  author =       {Chaitanya Chemudugunta},
  title =        {Text Mining with Probabilistic Topic Models: Applications in Information Retrieval and Concept Modeling},
  publisher = {LAP Lambert Academic Publishing},
  year =    {2010},
}
  @masterthesis{magnus,
  author =       {Magnus Bender},
  title =        {Betrachtung eines statistischen Topic-Modells zur Repr채sentation wechselnder Dokumente},
  School = {Universit채t zu L체beck},
  year =    {2019},
  note= {Bachelorarbeit},
}
  @techreport{t0,
  author =       {Aman Ahuja and Wei Wei and Kathleen Carley},
  title =        {Topic modeling in large scale social network data},
  institution = {Institute of Software Research, School of Computer Science, Pittsburgh},
  year =    {2015},
}
  @techreport{t1,
  author =       {Shaymaa Mohammed and Salam Al-augby},
  title =        {LSA \& LDA Topic Modeling Classification: Comparison study on E-books},
  institution = {Department of Computer Science, Faculty of Computer Science and Mathamatics, University of Kufa, Iraq},
  year =    {2019},
}
  @techreport{t3,
  author =       {P. Anupriya and S. Karpagavalli},
  title =        {LDA based topic modeling of journal abstracts},
  institution = {IEEE},
  note= {International Conference on Advanced Computing and Communication Systems},
  year =    {2015},
}
  @techreport{t5,
  author =       {Loulwah AlSumait and Daniel Barbara and James Gentle and Carlotta Domeniconi},
  title =        {Topic Significance Ranking of LDA Generative Models},
  institution = {Department of Computer Science, George Mason University},
  year =    {2009},
}
  @techreport{t6,
  author =       {Runzhe Yang},
  title =        {Topic Models (I)},
  institution = {Princeton University, Department of Computer Science},
  year =    {2019},
}
  @misc{statista,
  author =       {F. Tenzer},
  title =        {Prognose zum Volumen der j채hrlich generierten digitalen Datenmenge weltweit in den Jahren 2018 und 2025},
  year =    {2020},
}
